{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmoQ4FcezQmMpBlyg8qNwZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarasti2/AI_UdeA_2024-1/blob/main/fase-2/generate-data-and-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Configuraciones iniciales del entorno de trabajo"
      ],
      "metadata": {
        "id": "hVdV3Ppizzdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sVA0uFUyyy0y"
      },
      "outputs": [],
      "source": [
        "# Cargar las librerias que se usaran\n",
        "import numpy as np # Algebra lineal\n",
        "import pandas as pd # Dataframe tabulares\n",
        "import os # Permite utilizar funcionalidades del sistema operativo\n",
        "import seaborn as sns # Graficas estadisticas\n",
        "from sklearn.model_selection import train_test_split # Creación de subconjuntos\n",
        "from sklearn.preprocessing import LabelEncoder # Codificar etiquetas\n",
        "import xgboost as xgb # Algoritmo para la generación de modelos xgboost\n",
        "import matplotlib.pyplot as plt # Graficas\n",
        "from matplotlib.pyplot import figure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos desde Kaggle\n",
        "# ¡IMPORTANTE! subir el archivo .json, que representa el \"Token\" de Kaggle que\n",
        "# se genera según las instrucciones en el readme\n",
        "os.environ['KAGGLE_CONFIG_DIR']=\".\"\n",
        "!kaggle competitions download -c predicting-red-hat-business-value\n",
        "!unzip predicting-red-hat-business-value.zip"
      ],
      "metadata": {
        "id": "I4_Gd91X0UjM",
        "outputId": "0aa2b2f1-1c46-4b11-addd-371a3f1e99c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "predicting-red-hat-business-value.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  predicting-red-hat-business-value.zip\n",
            "replace act_test.csv.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Cargar bases de datos"
      ],
      "metadata": {
        "id": "MiPk4JiI0X6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La base de datos esta compuesta por una de personas, y otra de las actividades\n",
        "# que hacen las personas, cada persona tiene un identificador unico que permite\n",
        "# crea una sola base con ambas informaciones.\n",
        "\n",
        "train_df = pd.read_csv('act_train.csv.zip')\n",
        "people_df = pd.read_csv('people.csv.zip')\n"
      ],
      "metadata": {
        "id": "kyjg37gW4Fzf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Crear una base de datos consolidada"
      ],
      "metadata": {
        "id": "aHQ9K-ST8E8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Por la cantidad de valores vacios, se procedera a eliminar los char_#\n",
        "\n",
        "train_df = train_df.drop(['char_1', 'char_2', 'char_3',\n",
        "                          'char_4', 'char_5', 'char_6',\n",
        "                         'char_7', 'char_8', 'char_9',\n",
        "                         'char_10'], axis=1)\n",
        "\n",
        "# Se une por el identificador unico de persona\n",
        "train_df.set_index('people_id')\n",
        "people_df.set_index('people_id')\n",
        "df = pd.merge(train_df, people_df)\n",
        "\n",
        "# Dar el formato adecuado a las columnas\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['isweekend'] = (df['date'].dt.weekday >= 5).astype(int)\n",
        "df = df.drop('date', axis = 1)"
      ],
      "metadata": {
        "id": "MYIsgzSv8KAJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocesamiento"
      ],
      "metadata": {
        "id": "ZN9JggwB9AXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir las columnas en categoricas y numericas\n",
        "categorical_features = []\n",
        "numeric_features = []\n",
        "features = df.columns.values.tolist()\n",
        "for col in features:\n",
        "    if df[col].dtype != 'object':\n",
        "        numeric_features.append(col)\n",
        "    else:\n",
        "        categorical_features.append(col)\n",
        "\n",
        "# Codificar las columnas categoricas para que sean interpretables por el algoritmo\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(df[col].astype(str).values))\n",
        "    df[col] = le.transform(list(df[col].astype(str).values))\n",
        "\n",
        "# Creación de los sub-conjuntos de prueba y verificación\n",
        "y = df['outcome']\n",
        "X = df.drop('outcome', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "7Ur2-20vAAMd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "VPApWzKJ-xxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se usara un xgboost debido a que es un problema de clasificación con una alta\n",
        "# cantidad de datos\n",
        "\n",
        "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=10, learning_rate=0.05, use_label_encoder=False)\n",
        "gbm = gbm.fit(X_train, y_train)\n",
        "\n",
        "# Guardar modelo\n",
        "with open(\"model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(gbm, file)"
      ],
      "metadata": {
        "id": "OGGQy_UN-1Ai"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir el modelo guardado para verificar su funcionamiento\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    _gbm = pickle.load(file)\n",
        "\n",
        "# Verificación del rendimiento del modelo, en este caso se usara el criterio\n",
        "# de exactitud\n",
        "print(\"Exactitud conjunto de entrenamiento: {:.3f}\".format(_gbm.score(X_train, y_train)))\n",
        "print(\"Exactitud conjunto de verificacion: {:.3f}\".format(_gbm.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57jkyP5nAjtM",
        "outputId": "dfb8114c-f1b0-4e6a-8ad1-a373640f03ee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud conjunto de entrenamiento: 0.856\n",
            "Exactitud conjunto de verificacion: 0.854\n"
          ]
        }
      ]
    }
  ]
}